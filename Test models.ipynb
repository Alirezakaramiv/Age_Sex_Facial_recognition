{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "incoming-chemical",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "138cb073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import operator\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-necessity",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "482b6362",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_sex_models = keras.models.load_model('./age_sex_model.hdf5')\n",
    "\n",
    "facial_model = keras.models.load_model('./facial_exprassion_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-vienna",
   "metadata": {},
   "source": [
    "# Preprocessing inputs functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "546f9a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender(s):\n",
    "    if float(s) < 0.4:\n",
    "        return str('man')\n",
    "    else:\n",
    "        return str('woman')\n",
    "\n",
    "def facial_pred_decode(list_):\n",
    "#     dictionary = {0:'anger', 1:'contempt', 2:'disgust', 3:'fear', 4:'happy', 5:'sadness',6:'surprise'}\n",
    "    dictionary = {0:'anger', 1:'disgust', 2:'fear', 3:'happy', 4:'natural', 5:'sad',6:'surprise'}\n",
    "    _ , min_value = min(enumerate(list_), key=operator.itemgetter(1))\n",
    "    max_index_1, _ = max(enumerate(list_), key=operator.itemgetter(1))\n",
    "    first_rank = dictionary[max_index_1]\n",
    "    list_[max_index_1] = min_value\n",
    "    max_index_2, _ = max(enumerate(list_), key=operator.itemgetter(1))\n",
    "    second_rank = dictionary[max_index_2]\n",
    "    return  first_rank , second_rank\n",
    "\n",
    "def face_detect(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    model = MTCNN()\n",
    "    face = model.detect_faces(img)\n",
    "    boundingbox = face[0]['box']\n",
    "    img = img[boundingbox[1]+10:boundingbox[1]+boundingbox[2]+20 , boundingbox[0]-10:boundingbox[0]+boundingbox[3]-10]\n",
    "    return img\n",
    "\n",
    "def resize(img , height , width):\n",
    "    img = tf.image.resize(img , (height , width) , method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    return img\n",
    "\n",
    "def normalize(image):\n",
    "    image = (image / 255)\n",
    "    return image\n",
    "\n",
    "def load_img(image_path):\n",
    "    main = cv2.imread(image_path)\n",
    "    img = face_detect(image_path)\n",
    "#     img = tf.image.decode_image(img , 3 ,expand_animations=False)\n",
    "    img = tf.cast(img , tf.float32)\n",
    "    img = resize(img , 224 , 224)\n",
    "    img = normalize(img)\n",
    "    return main , img\n",
    "\n",
    "def load_img_realtime(img):\n",
    "    img = tf.cast(img , tf.float32)\n",
    "    img = resize(img , 224 , 224)\n",
    "    img = normalize(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-avenue",
   "metadata": {},
   "source": [
    "# Infrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "young-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infrence(img_path):\n",
    "    main ,img = load_img(img_path)\n",
    "    img_d = tf.expand_dims(img, axis=0)\n",
    "#     print('main shape is ',main.shape)\n",
    "#     print('dim shape is ',img_d.shape)\n",
    "    pred_sex_age = age_sex_models.predict(img_d)\n",
    "    pred_facial = facial_model.predict(img_d)\n",
    "### get predicate labels\n",
    "    age_label = float(pred_sex_age[0][0][0])\n",
    "    sex_label = gender(int(pred_sex_age[1][0][0]))\n",
    "    facial = facial_pred_decode(pred_facial[0])\n",
    "#     plt.imshow(face_detect(img_path))\n",
    "#     plt.show()\n",
    "    plt.imshow(main , cmap='gray')\n",
    "    plt.show()\n",
    "#     print(' sex = {}\\n age = {}\\n facial = {}'.format(sex_label , np.round(age_label) , facial))\n",
    "    return sex_label , np.round(age_label) , facial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "confident-windsor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/conv2d/Conv2D' defined at (most recent call last):\n    File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/lib/python3/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/oem/.local/lib/python3.9/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/usr/lib/python3/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/lib/python3/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/lib/python3/dist-packages/tornado/ioloop.py\", line 688, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/lib/python3/dist-packages/tornado/ioloop.py\", line 741, in _run_callback\n      ret = callback()\n    File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 814, in inner\n      self.ctx_run(self.run)\n    File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 378, in dispatch_queue\n      yield self.process_one()\n    File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 250, in wrapper\n      runner = Runner(ctx_run, result, future, yielded)\n    File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 741, in __init__\n      self.ctx_run(self.run)\n    File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 362, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 265, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 540, in execute_request\n      self.do_execute(\n    File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/lib/python3/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/lib/python3/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2886, in run_cell\n      result = self._run_cell(\n    File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2932, in _run_cell\n      return runner(coro)\n    File \"/usr/lib/python3/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3155, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3347, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3427, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-5-5037857d42ff>\", line 1, in <module>\n      interface('./image/test4.png')\n    File \"<ipython-input-4-e82c78b3f809>\", line 2, in interface\n      main ,img = load_img(img_path)\n    File \"<ipython-input-3-d2efc2c6ea16>\", line 36, in load_img\n      img = face_detect(image_path)\n    File \"<ipython-input-3-d2efc2c6ea16>\", line 21, in face_detect\n      face = model.detect_faces(img)\n    File \"/home/oem/.local/lib/python3.9/site-packages/mtcnn/mtcnn.py\", line 300, in detect_faces\n      result = stage(img, result[0], result[1])\n    File \"/home/oem/.local/lib/python3.9/site-packages/mtcnn/mtcnn.py\", line 342, in __stage1\n      out = self._pnet.predict(img_y)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 2033, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1845, in predict_function\n      return step_function(self, iterator)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1834, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1823, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1791, in predict_step\n      return self(x, training=False)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 250, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 225, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv2d/Conv2D'\nDNN library is not found.\n\t [[{{node model/conv2d/Conv2D}}]] [Op:__inference_predict_function_7918]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5037857d42ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./image/test4.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-e82c78b3f809>\u001b[0m in \u001b[0;36minterface\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimg_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     print('main shape is ',main.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     print('dim shape is ',img_d.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d2efc2c6ea16>\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_detect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;31m#     img = tf.image.decode_image(img , 3 ,expand_animations=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d2efc2c6ea16>\u001b[0m in \u001b[0;36mface_detect\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMTCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mboundingbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'box'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mboundingbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mboundingbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mboundingbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m20\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mboundingbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mboundingbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mboundingbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/mtcnn/mtcnn.py\u001b[0m in \u001b[0;36mdetect_faces\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;31m# We pipe here each of the stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mtotal_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/mtcnn/mtcnn.py\u001b[0m in \u001b[0;36m__stage1\u001b[0;34m(self, image, scales, stage_status)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0mimg_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mout0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/conv2d/Conv2D' defined at (most recent call last):\n    File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/lib/python3/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/oem/.local/lib/python3.9/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/usr/lib/python3/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/lib/python3/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/lib/python3/dist-packages/tornado/ioloop.py\", line 688, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/lib/python3/dist-packages/tornado/ioloop.py\", line 741, in _run_callback\n      ret = callback()\n    File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 814, in inner\n      self.ctx_run(self.run)\n    File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 378, in dispatch_queue\n      yield self.process_one()\n    File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 250, in wrapper\n      runner = Runner(ctx_run, result, future, yielded)\n    File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 741, in __init__\n      self.ctx_run(self.run)\n    File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 362, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 265, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 540, in execute_request\n      self.do_execute(\n    File \"/usr/lib/python3/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/lib/python3/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/lib/python3/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2886, in run_cell\n      result = self._run_cell(\n    File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2932, in _run_cell\n      return runner(coro)\n    File \"/usr/lib/python3/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3155, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3347, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3427, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-5-5037857d42ff>\", line 1, in <module>\n      interface('./image/test4.png')\n    File \"<ipython-input-4-e82c78b3f809>\", line 2, in interface\n      main ,img = load_img(img_path)\n    File \"<ipython-input-3-d2efc2c6ea16>\", line 36, in load_img\n      img = face_detect(image_path)\n    File \"<ipython-input-3-d2efc2c6ea16>\", line 21, in face_detect\n      face = model.detect_faces(img)\n    File \"/home/oem/.local/lib/python3.9/site-packages/mtcnn/mtcnn.py\", line 300, in detect_faces\n      result = stage(img, result[0], result[1])\n    File \"/home/oem/.local/lib/python3.9/site-packages/mtcnn/mtcnn.py\", line 342, in __stage1\n      out = self._pnet.predict(img_y)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 2033, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1845, in predict_function\n      return step_function(self, iterator)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1834, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1823, in run_step\n      outputs = model.predict_step(data)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 1791, in predict_step\n      return self(x, training=False)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 250, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/oem/.local/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 225, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv2d/Conv2D'\nDNN library is not found.\n\t [[{{node model/conv2d/Conv2D}}]] [Op:__inference_predict_function_7918]"
     ]
    }
   ],
   "source": [
    "infrence('./image/test4.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-activity",
   "metadata": {},
   "source": [
    "# Real Time part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50536142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model(img):\n",
    "#     img = load_img_realtime(img)\n",
    "#     img_d = tf.expand_dims(img, axis=0)\n",
    "#     pred_sex_age = age_sex_models.predict(img_d)\n",
    "#     pred_facial = facial_model.predict(img_d)\n",
    "# ### get predicate labels\n",
    "#     age_label = float(pred_sex_age[0][0][0])\n",
    "#     sex_label = gender(int(pred_sex_age[1][0][0]))\n",
    "#     facial = facial_pred_decode(pred_facial[0])\n",
    "#     return sex_label , np.round(age_label) , facial\n",
    "\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# face = cv2.CascadeClassifier('harrcascade_frontalface_default.xml')\n",
    "# while 1:\n",
    "#     ret,frame = cap.read()\n",
    "#     if ret:\n",
    "#         face1 = face.detectMultiScale(frame)\n",
    "#         for x,y,w,h in face1:\n",
    "#             img = frame[y:y+w , x:x+h]\n",
    "#             sex , age , facial = model(img)\n",
    "#             cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)      \n",
    "#             cv2.putText(img=frame, text=sex, org=(x+20, y),\n",
    "#                     fontFace=cv2.FONT_HERSHEY_TRIPLEX, fontScale=1, color=(0, 255, 0), thickness=2)\n",
    "#             cv2.putText(img=frame, text=str(age), org=(x+40, y),\n",
    "#                                         fontFace=cv2.FONT_HERSHEY_TRIPLEX, fontScale=1, color=(0, 0, 255),thickness=2)\n",
    "#             cv2.putText(img=frame, text=facial , org=(x+60, y),\n",
    "#                     fontFace=cv2.FONT_HERSHEY_TRIPLEX, fontScale=1, color=(255, 0, 0),thickness=2)\n",
    "#             cv2.imshow('frame', frame)\n",
    "\n",
    "#             k = cv2.waitKey(33)\n",
    "#             if k == -1:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 break\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-preparation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
